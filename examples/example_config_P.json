{
  "data": {
    "data": {
      "task_type": "dl",
      "main_task": "image",
      "sub_task": "Image Classification",
      "data_format": "imagefolder",
      "data_type": "folder"
    },
    "dataloading": "def get_loader(root, batch_size, split):\n    class CustomImageDataset(Dataset):\n        def __init__(self, root_dir, split, transform=None):\n            self.root_dir = f\"{root_dir}/{split}\"\n            self.transform = transform\n            self.image_paths = list(Path(self.root_dir).rglob(\"*.jpg\")) + list(Path(self.root_dir).rglob(\"*.png\"))\n            self.classes = sorted({p.parent.name for p in self.image_paths})\n            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n\n        def __len__(self):\n            return len(self.image_paths)\n\n        def __getitem__(self, idx):\n            image_path = self.image_paths[idx]\n            image = Image.open(image_path).convert(\"RGB\")\n            label = self.class_to_idx[image_path.parent.name]\n            if self.transform:\n                image = self.transform(image)\n            return {\"image\": image, \"label\": label}\n\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    dataset = CustomImageDataset(root, split, transform=transform)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=(split==\"train\"))\n    return loader",
    "preprocessing": [
      {
        "name": "Resize",
        "params": { "size": [224, 224] }
      },
      {
        "name": "Normalize",
        "params": {
          "mean": [0.485, 0.456, 0.406],
          "std": [0.229, 0.224, 0.225]
        }
      }
    ],
    "model": {
      "use_pretrained": true,
      "pretrained": {
        "name": "resnet50",
        "params": {}
      },
      "layers": null
    },
    "training": {
      "batch_size": 32,
      "learning_rate": 0.001,
      "epochs": 10,
      "weight_decay": 0.0001,
      "optimizer": {
        "name": "Adam",
        "params": {}
      },
      "scheduler": null,
      "loss": {
        "name": "CrossEntropyLoss",
        "params": {}
      },
      "metrics": [
        {
          "name": "accuracy",
          "params":{}
        }
      ],
      "early_stopping": {
        "enabled": true,
        "params": {
          "patience": 3,
          "metric": "val_loss"
        }
      },
      "monitoring": ["use_tensorboard", "resource_alerts"]
    }
  }
}